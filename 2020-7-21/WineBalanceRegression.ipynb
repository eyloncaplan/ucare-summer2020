{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, precision_recall_curve, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv(\"~/ucare-summer2020/datasets/winequality-white.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.drop(columns=['quality'])\n",
    "y = wine['quality']\n",
    "y = y > 5\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of good wines to total wines: 0.66\n",
      "Ratio of bad wines to total wines: 0.34\n"
     ]
    }
   ],
   "source": [
    "good_total_ratio = np.mean(y_train)\n",
    "bad_total_ratio = 1 - good_total_ratio\n",
    "print(\"Ratio of good wines to total wines: %.2f\" % good_total_ratio)\n",
    "print(\"Ratio of bad wines to total wines: %.2f\" % bad_total_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_clf(clf, X_train, X_test, y_train, y_test):\n",
    "    y_train_predicted = clf.predict(X_train)\n",
    "    y_test_predicted = clf.predict(X_test)\n",
    "    print(\"\\nTrain Accuracy: \", np.mean(y_train_predicted == y_train))\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"\\nTest Accuracy: \", np.mean(y_test_predicted == y_test))\n",
    "    print(\"\\nTest Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "\n",
    "    precision_test = precision_score(y_test, y_test_predicted) \n",
    "    print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "    recall_test = recall_score(y_test, y_test_predicted)\n",
    "    print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "    f1_test = f1_score(y_test, y_test_predicted)\n",
    "    print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_weight_report():\n",
    "    print(\"NO CLASS WEIGHTS:\")\n",
    "    param_grid = {'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "                  'max_iter': [20000],\n",
    "                  'C': [0.0001, 0.001, 0.1, 0.5, 1, 10]}\n",
    "    lg_reg = LogisticRegression()\n",
    "    lg_reg_cv = GridSearchCV(lg_reg, param_grid, scoring='accuracy',\n",
    "                            cv=5, verbose=1, n_jobs=-1)\n",
    "    lg_reg_cv.fit(X_train, y_train)\n",
    "    params_optimal = lg_reg_cv.best_params_\n",
    "    print(\"Optimal Hyperparameter Values: \", params_optimal)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    report_clf(lg_reg_cv, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"WITH CLASS WEIGHTS:\")\n",
    "    param_grid = {'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "                  'max_iter': [20000],\n",
    "                  'C': [0.0001, 0.001, 0.1, 0.5, 1, 10]}\n",
    "    lg_reg = LogisticRegression(class_weight={0:good_total_ratio, 1:bad_total_ratio})\n",
    "    lg_reg_cv = GridSearchCV(lg_reg, param_grid, scoring='accuracy',\n",
    "                            cv=5, verbose=1, n_jobs=-1)\n",
    "    lg_reg_cv.fit(X_train, y_train)\n",
    "    params_optimal = lg_reg_cv.best_params_\n",
    "    print(\"Optimal Hyperparameter Values: \", params_optimal)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    report_clf(lg_reg_cv, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO CLASS WEIGHTS:\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Hyperparameter Values:  {'C': 10, 'max_iter': 20000, 'solver': 'liblinear'}\n",
      "\n",
      "\n",
      "\n",
      "Train Accuracy:  0.7575293517100562\n",
      "-----------------------------------------\n",
      "\n",
      "Test Accuracy:  0.7418367346938776\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[153 168]\n",
      " [ 85 574]]\n",
      "\n",
      "Test Precision = 0.773585\n",
      "Test Recall = 0.871017\n",
      "Test F1 Score = 0.819415\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.48      0.55       321\n",
      "           1       0.77      0.87      0.82       659\n",
      "\n",
      "    accuracy                           0.74       980\n",
      "   macro avg       0.71      0.67      0.68       980\n",
      "weighted avg       0.73      0.74      0.73       980\n",
      "\n",
      "WITH CLASS WEIGHTS:\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed:   21.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Hyperparameter Values:  {'C': 10, 'max_iter': 20000, 'solver': 'liblinear'}\n",
      "\n",
      "\n",
      "\n",
      "Train Accuracy:  0.7164369576314447\n",
      "-----------------------------------------\n",
      "\n",
      "Test Accuracy:  0.7153061224489796\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[232  89]\n",
      " [190 469]]\n",
      "\n",
      "Test Precision = 0.840502\n",
      "Test Recall = 0.711684\n",
      "Test F1 Score = 0.770748\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.72      0.62       321\n",
      "           1       0.84      0.71      0.77       659\n",
      "\n",
      "    accuracy                           0.72       980\n",
      "   macro avg       0.70      0.72      0.70       980\n",
      "weighted avg       0.75      0.72      0.72       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "class_weight_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights increased precision but reduced recall.\n"
     ]
    }
   ],
   "source": [
    "print(\"Class weights increased precision but reduced recall.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_over_sampler():\n",
    "    print(\"UNDERSAMPLED:\")\n",
    "    rus = RandomUnderSampler() \n",
    "    X_resampled, y_resampled = rus.fit_sample(X_train, y_train)\n",
    "    \n",
    "    param_grid = {'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "                  'max_iter': [20000],\n",
    "                  'C': [0.0001, 0.001, 0.1, 1, 10]}\n",
    "    lg_reg = LogisticRegression()\n",
    "    lg_reg_cv = GridSearchCV(lg_reg, param_grid, scoring='accuracy',\n",
    "                            cv=5, verbose=1, n_jobs=-1)\n",
    "    lg_reg_cv.fit(X_resampled, y_resampled)\n",
    "    params_optimal = lg_reg_cv.best_params_\n",
    "    print(\"Optimal Hyperparameter Values: \", params_optimal)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    report_clf(lg_reg_cv, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    \n",
    "    print(\"OVERSAMPLED:\")\n",
    "    ada = ADASYN()\n",
    "    X_resampled, y_resampled = ada.fit_sample(X_train, y_train)\n",
    "    \n",
    "    param_grid = {'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "                  'max_iter': [20000],\n",
    "                  'C': [0.0001, 0.001, 0.1, 1, 10]}\n",
    "    lg_reg = LogisticRegression()\n",
    "    lg_reg_cv = GridSearchCV(lg_reg, param_grid, scoring='accuracy',\n",
    "                            cv=5, verbose=1, n_jobs=-1)\n",
    "    lg_reg_cv.fit(X_resampled, y_resampled)\n",
    "    params_optimal = lg_reg_cv.best_params_\n",
    "    print(\"Optimal Hyperparameter Values: \", params_optimal)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    report_clf(lg_reg_cv, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNDERSAMPLED:\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:   51.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Hyperparameter Values:  {'C': 10, 'max_iter': 20000, 'solver': 'lbfgs'}\n",
      "\n",
      "\n",
      "\n",
      "Train Accuracy:  0.7179683511995917\n",
      "-----------------------------------------\n",
      "\n",
      "Test Accuracy:  0.7193877551020408\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[233  88]\n",
      " [187 472]]\n",
      "\n",
      "Test Precision = 0.842857\n",
      "Test Recall = 0.716237\n",
      "Test F1 Score = 0.774405\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.73      0.63       321\n",
      "           1       0.84      0.72      0.77       659\n",
      "\n",
      "    accuracy                           0.72       980\n",
      "   macro avg       0.70      0.72      0.70       980\n",
      "weighted avg       0.75      0.72      0.73       980\n",
      "\n",
      "OVERSAMPLED:\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:   52.4s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Hyperparameter Values:  {'C': 10, 'max_iter': 20000, 'solver': 'newton-cg'}\n",
      "\n",
      "\n",
      "\n",
      "Train Accuracy:  0.7240939254721797\n",
      "-----------------------------------------\n",
      "\n",
      "Test Accuracy:  0.7214285714285714\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[231  90]\n",
      " [183 476]]\n",
      "\n",
      "Test Precision = 0.840989\n",
      "Test Recall = 0.722307\n",
      "Test F1 Score = 0.777143\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.72      0.63       321\n",
      "           1       0.84      0.72      0.78       659\n",
      "\n",
      "    accuracy                           0.72       980\n",
      "   macro avg       0.70      0.72      0.70       980\n",
      "weighted avg       0.75      0.72      0.73       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "under_over_sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both over and undersampling have increased precision but greatly reduced recall. All methods so far have reduced accuracy and F1 score (or had the same F1 score).\n"
     ]
    }
   ],
   "source": [
    "print(\"Both over and undersampling have increased precision but greatly reduced recall. All methods so far have reduced accuracy and F1 score (or had the same F1 score).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

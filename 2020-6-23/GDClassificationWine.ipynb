{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, precision_recall_curve, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv(\"~/datasets/winequality-white.csv\", sep=\";\")\n",
    "wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.drop(columns=['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = wine['quality']\n",
    "y = y > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "4893    1\n",
       "4894    0\n",
       "4895    1\n",
       "4896    1\n",
       "4897    1\n",
       "Name: quality, Length: 4898, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.astype(int)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 360 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 212 tasks      | elapsed:   51.9s\n",
      "[Parallel(n_jobs=-1)]: Done 462 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 812 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed: 10.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (accuracy): 0.752425\n",
      "Optimal Hyperparameter Values:  {'C': 10, 'max_iter': 3000, 'solver': 'lbfgs', 'tol': 0.001}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "             'tol': [1e-3, 1e-4, 1e-5], 'max_iter': [3000, 5000, 10000, 20000],\n",
    "             'C': [0.0001, 0.001, 0.1, 0.5, 1, 10]}\n",
    "lg_reg = LogisticRegression()\n",
    "lg_reg_cv = GridSearchCV(lg_reg, param_grid, scoring='accuracy',\n",
    "                        cv=3, verbose=1, n_jobs=-1)\n",
    "lg_reg_cv.fit(X_train, y_train)\n",
    "params_optimal = lg_reg_cv.best_params_\n",
    "print(\"Best Score (accuracy): %f\" % lg_reg_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, max_iter=3000, tol=0.001)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_reg_clf = LogisticRegression(**params_optimal)\n",
    "lg_reg_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Iterations: [521]\n",
      "\n",
      "Weight Intercept: [-4.36260889]\n",
      "Weight Coefficients: [[-1.89575431e-01 -6.79975761e+00 -5.10352048e-02  6.70094980e-02\n",
      "  -3.73619264e-01  1.38572845e-02 -2.23070047e-03 -4.11684663e+00\n",
      "   6.51117247e-02  1.39814849e+00  1.05612563e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of Iterations:\", lg_reg_clf.n_iter_ )\n",
    "print(\"\\nWeight Intercept:\", lg_reg_clf.intercept_ )\n",
    "print(\"Weight Coefficients:\", lg_reg_clf.coef_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy:  0.7408163265306122\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[154 167]\n",
      " [ 87 572]]\n",
      "\n",
      "Test Precision = 0.774019\n",
      "Test Recall = 0.867982\n",
      "Test F1 Score = 0.818312\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.48      0.55       321\n",
      "           1       0.77      0.87      0.82       659\n",
      "\n",
      "    accuracy                           0.74       980\n",
      "   macro avg       0.71      0.67      0.68       980\n",
      "weighted avg       0.73      0.74      0.73       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted_GD = lg_reg_clf.predict(X_test)\n",
    "\n",
    "accuracy_score_test_GD = np.mean(y_test_predicted == y_test)\n",
    "print(\"\\nTest Accuracy: \", accuracy_score_test_GD)\n",
    "\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted_GD))\n",
    "\n",
    "\n",
    "precision_test_GD = precision_score(y_test, y_test_predicted_GD) \n",
    "print(\"\\nTest Precision = %f\" % precision_test_GD)\n",
    "\n",
    "recall_test_GD = recall_score(y_test, y_test_predicted_GD)\n",
    "print(\"Test Recall = %f\" % recall_test_GD)\n",
    "\n",
    "\n",
    "f1_test_GD = f1_score(y_test, y_test_predicted_GD)\n",
    "print(\"Test F1 Score = %f\" % f1_test_GD)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted_GD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1296 candidates, totalling 3888 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1952 tasks      | elapsed:   20.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (accuracy): 0.699081\n",
      "Optimal Hyperparameter Values:  {'alpha': 0.001, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log', 'max_iter': 3000, 'penalty': 'l2', 'tol': 1e-08}\n",
      "\n",
      "\n",
      "CPU times: user 3.59 s, sys: 151 ms, total: 3.74 s\n",
      "Wall time: 44 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3888 out of 3888 | elapsed:   43.8s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "warnings.filterwarnings('ignore')\n",
    "param_grid = {'alpha': [0.05, 0.01, 0.001],\n",
    "              'penalty' : [\"l2\"],\n",
    "              'learning_rate': [\"constant\", \"optimal\", \"invscaling\", \"adaptive\"], \n",
    "              'max_iter':[500, 1000, 3000, 7000],\n",
    "              'eta0': [0.1, 0.01, 0.001],\n",
    "              'tol': [1e-3, 1e-5, 1e-8],\n",
    "              'loss': ['hinge', 'log', 'modified_huber']}\n",
    "sgd_clf = SGDClassifier()\n",
    "sgd_clf_cv = GridSearchCV(sgd_clf, param_grid, scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n",
    "sgd_clf_cv.fit(X_train, y_train)\n",
    "params_optimal = sgd_clf_cv.best_params_\n",
    "print(\"Best Score (accuracy): %f\" % sgd_clf_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, eta0=0.1, learning_rate='adaptive', loss='log',\n",
       "              max_iter=3000, tol=1e-08)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier(**params_optimal)\n",
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy:  0.6887755102040817\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[169 152]\n",
      " [153 506]]\n",
      "\n",
      "Test Precision = 0.768997\n",
      "Test Recall = 0.767830\n",
      "Test F1 Score = 0.768413\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.53      0.53       321\n",
      "           1       0.77      0.77      0.77       659\n",
      "\n",
      "    accuracy                           0.69       980\n",
      "   macro avg       0.65      0.65      0.65       980\n",
      "weighted avg       0.69      0.69      0.69       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted_SGD = sgd.predict(X_test)\n",
    "\n",
    "accuracy_score_test_SGD = np.mean(y_test_predicted_SGD == y_test)\n",
    "print(\"\\nTest Accuracy: \", accuracy_score_test_SGD)\n",
    "\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted_SGD))\n",
    "\n",
    "\n",
    "precision_test_SGD = precision_score(y_test, y_test_predicted_SGD) \n",
    "print(\"\\nTest Precision = %f\" % precision_test_SGD)\n",
    "\n",
    "recall_test_SGD = recall_score(y_test, y_test_predicted_SGD)\n",
    "print(\"Test Recall = %f\" % recall_test_SGD)\n",
    "\n",
    "\n",
    "f1_test_SGD = f1_score(y_test, y_test_predicted_SGD)\n",
    "print(\"Test F1 Score = %f\" % f1_test_SGD)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted_SGD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GRADIENT DESCENT REPORT:\n",
      "\n",
      "Test Accuracy:  0.7408163265306122\n",
      "\n",
      "Test Precision = 0.774019\n",
      "Test Recall = 0.867982\n",
      "Test F1 Score = 0.818312\n",
      "--------------------------------------\n",
      "\n",
      "STOCHASTIC GRADIENT DESCENT REPORT:\n",
      "\n",
      "Test Accuracy:  0.6887755102040817\n",
      "\n",
      "Test Precision = 0.768997\n",
      "Test Recall = 0.767830\n",
      "Test F1 Score = 0.768413\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGRADIENT DESCENT REPORT:\")\n",
    "print(\"\\nTest Accuracy: \", accuracy_score_test_GD)\n",
    "print(\"\\nTest Precision = %f\" % precision_test_GD)\n",
    "print(\"Test Recall = %f\" % recall_test_GD)\n",
    "print(\"Test F1 Score = %f\" % f1_test_GD)\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "print(\"\\nSTOCHASTIC GRADIENT DESCENT REPORT:\")\n",
    "print(\"\\nTest Accuracy: \", accuracy_score_test_SGD)\n",
    "print(\"\\nTest Precision = %f\" % precision_test_SGD)\n",
    "print(\"Test Recall = %f\" % recall_test_SGD)\n",
    "print(\"Test F1 Score = %f\" % f1_test_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    980.000000\n",
       "mean       0.672449\n",
       "std        0.469560\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: quality, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Note that guessing 'good' wine every time would yield an accuracy of 0.672, which is almost the same as the stochastic gradient descent model's accuracy and quite close to the normal gradient descent model's accuracy.\n",
      "     This seems to show that the two models being used are probably biased and are not fitting properly.\n"
     ]
    }
   ],
   "source": [
    "print(\"     Note that guessing 'good' wine every time would yield an accuracy of 0.672, which is almost the same as the stochastic gradient descent model's accuracy and quite close to the normal gradient descent model's accuracy.\")\n",
    "print(\"     This seems to show that the two models being used are probably biased and are not fitting properly.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
